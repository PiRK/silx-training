{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input/output\n",
    "============"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HDF5 using silx\n",
    "===============\n",
    "\n",
    "Read example\n",
    "------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import silx.io.utils\n",
    "\n",
    "h5file = silx.io.utils.load('data/test.h5')\n",
    "\n",
    "# print available names at the first level\n",
    "print(h5file['/'].keys())\n",
    "\n",
    "# reaching a dataset from a sub group\n",
    "dataset = h5file['/diff_map_0000/data/map']\n",
    "\n",
    "# using size and types to not read the full stored data\n",
    "print(dataset.shape, dataset.size, dataset.dtype)\n",
    "\n",
    "# datasets mimics numpy-array\n",
    "# read and apply the operation\n",
    "a = 2 * dataset[0, 5]\n",
    "# copy the data and store it as a numpy-array\n",
    "b = dataset[...]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write example\n",
    "-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import h5py\n",
    "\n",
    "data = numpy.arange(10000.0)\n",
    "data.shape = 100, 100\n",
    "\n",
    "# write\n",
    "h5file = h5py.File('my_first_one.h5', access='w')\n",
    "\n",
    "# write data into a dataset from the root\n",
    "h5file['/data1'] = data\n",
    "\n",
    "# write data into a dataset from group1\n",
    "h5file['/group1/data2'] = data\n",
    "\n",
    "h5file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specfile using silx\n",
    "==================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HDF5-like mapping\n",
    "-----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import silx.io.utils\n",
    "\n",
    "h5file = silx.io.utils.load('data/test.h5')\n",
    "\n",
    "string = silx.io.utils.h5ls(h5file)\n",
    "print(string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python example\n",
    "--------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import silx.io.utils\n",
    "\n",
    "specdata = silx.io.utils.load('data/oleg.dat')\n",
    "\n",
    "# print available scans\n",
    "print(specdata['/'].keys())\n",
    "\n",
    "# print available measurements from the scan 94.1\n",
    "print(specdata['/94.1/measurement'].keys())\n",
    "\n",
    "# get data from measurement\n",
    "xdata = specdata['/94.1/measurement/Epoch']\n",
    "ydata = specdata['/94.1/measurement/bpmi']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EDF using FabIO\n",
    "==============="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading files\n",
    "-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import fabio\n",
    "\n",
    "image = fabio.open(\"data/medipix.edf\")\n",
    "\n",
    "# here is the data as a numpy array\n",
    "image.data\n",
    "\n",
    "# here is the header as key-value dictionary\n",
    "image.header\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing files\n",
    "-------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import fabio\n",
    "import numpy\n",
    "\n",
    "image = numpy.random.rand(10, 10)\n",
    "metadata = {'pixel_size': '0.2'}\n",
    "\n",
    "image = fabio.edfimage.edfimage(data=image, header=metadata)\n",
    "image.write('new.edf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File conversion\n",
    "==============="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With FabIO\n",
    "---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import fabio\n",
    "\n",
    "image = fabio.open('data/medipix.edf')\n",
    "image = image.convert('tif')\n",
    "image.save('filename.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ls -al filename.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spec file to HDF5\n",
    "-----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from silx.io.spectoh5 import write_spec_to_h5\n",
    "\n",
    "write_spec_to_h5('data/oleg.dat', 'oleg.h5', mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ls -al oleg.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise\n",
    "========\n",
    "\n",
    "1. Read the EDF file ``medipix.edf``.\n",
    "2. Process the data\n",
    "\n",
    "   - Create a mask for all the values below 10%.\n",
    "   - With the above mask, set the affected pixels to 10%.\n",
    "   - Optionally do the same for values above 90%.\n",
    "   - This clamp values between 10% and 90%\n",
    "\n",
    "3. Store the source, the mask of changed pixels and the result inside ``process.h5``, as below.\n",
    "\n",
    "   ![Output file structure](images/exercise-result.png)\n",
    "\n",
    "4. Load ``process.h5`` and list the root content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load data/medipix.edf\n",
    "# ...\n",
    "\n",
    "# Process the data\n",
    "# ...\n",
    "\n",
    "# Load process.h5 to write inside: the source, the mask and the result\n",
    "# ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
